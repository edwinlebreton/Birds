{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from data_handler import DataHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Activation, Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "\n",
    "\n",
    "def embeding(df):\n",
    "    df_copy = copy.deepcopy(df)\n",
    "    for header, values in df_copy.items():\n",
    "        df_copy[header] = pd.Categorical(df_copy[header])\n",
    "        df_copy[header] = df_copy[header].cat.codes\n",
    "    return df_copy\n",
    "\n",
    "def DA_Jitter(X, sigma=0.05):\n",
    "    myNoise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n",
    "    return X+myNoise\n",
    "\n",
    "def data_augmentation(data_arr,sigma):\n",
    "    newData_arr = data_arr[:,1:8]\n",
    "    newData_arr = DA_Jitter(newData_arr, sigma)\n",
    "\n",
    "    newData_arr = np.column_stack((data_arr[:,0],newData_arr,data_arr[:,8]))\n",
    "    newData_arr = newData_arr[newData_arr[:,-1] != 1]\n",
    "    return  newData_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# parse arguments\n",
    "## general\n",
    "arg_parser = argparse.ArgumentParser()\n",
    "arg_parser.add_argument('--working_path', default='.')\n",
    "\n",
    "## data\n",
    "arg_parser.add_argument('dataset_name', default='mimic3',\n",
    "                        help='The data files should be saved in [working_path]/data/[dataset_name] directory.')\n",
    "arg_parser.add_argument('label_name', default='mortality')\n",
    "arg_parser.add_argument('--max_timesteps', type=int, default=200, \n",
    "                        help='Time series of at most # time steps are used. Default: 200.')\n",
    "arg_parser.add_argument('--max_timestamp', type=int, default=48*60*60,\n",
    "                        help='Time series of at most # seconds are used. Default: 48 (hours).')\n",
    "\n",
    "## model\n",
    "arg_parser.add_argument('--recurrent_dim', type=lambda x: x and [int(xx) for xx in x.split(',')] or [], default='64')\n",
    "arg_parser.add_argument('--hidden_dim', type=lambda x: x and [int(xx) for xx in x.split(',')] or [], default='64')\n",
    "arg_parser.add_argument('--model', default='GRUD', choices=['GRUD', 'GRUforward', 'GRU0', 'GRUsimple'])\n",
    "arg_parser.add_argument('--use_bidirectional_rnn', default=False)\n",
    "                           \n",
    "## training\n",
    "arg_parser.add_argument('--pretrained_model_file', default=None,\n",
    "                        help='If pre-trained model is provided, training will be skipped.') # e.g., [model_name]_[i_fold].h5\n",
    "arg_parser.add_argument('--epochs', type=int, default=100)\n",
    "arg_parser.add_argument('--early_stopping_patience', type=int, default=10)\n",
    "arg_parser.add_argument('--batch_size', type=int, default=2)\n",
    "\n",
    "\n",
    "## set the actual arguments if running in notebook\n",
    "if not (__name__ == '__main__' and '__file__' in globals()):\n",
    "    # '''ARGS = arg_parser.parse_args([\n",
    "    #     'mimic3',\n",
    "    #     'mortality',\n",
    "    #     '--model', 'GRUD',\n",
    "    #     '--hidden_dim', '',\n",
    "    #     '--epochs', '100'\n",
    "    # ])'''\n",
    "    ARGS = arg_parser.parse_args([\n",
    "        'detection',\n",
    "        'risk_situation',\n",
    "        '--model', 'GRUD',\n",
    "        '--hidden_dim', '',\n",
    "        '--max_timestamp', '5807537',\n",
    "        '--epochs', '100'\n",
    "    ])\n",
    "else:\n",
    "    ARGS = arg_parser.parse_args()\n",
    "\n",
    "#print('Arguments:', ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get dataset\n",
    "dataset = DataHandler(\n",
    "    data_path=os.path.join(ARGS.working_path, 'data', ARGS.dataset_name), \n",
    "    label_name=ARGS.label_name, \n",
    "    max_steps=ARGS.max_timesteps,\n",
    "    max_timestamp=ARGS.max_timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6152\n",
      "0     526\n",
      "Name: risk_situation, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>step</th>\n",
       "      <th>gsr</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>skin_temp</th>\n",
       "      <th>calories</th>\n",
       "      <th>risk_situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1468</td>\n",
       "      <td>109</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1539</td>\n",
       "      <td>114</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1483</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1495</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1478</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1451</td>\n",
       "      <td>118</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1468</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1465</td>\n",
       "      <td>112</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1495</td>\n",
       "      <td>103</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>61</td>\n",
       "      <td>1475</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>44</td>\n",
       "      <td>155</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "      <td>49</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>65</td>\n",
       "      <td>194</td>\n",
       "      <td>117</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>-1</td>\n",
       "      <td>7406</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>-1</td>\n",
       "      <td>7494</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>-1</td>\n",
       "      <td>907</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>-1</td>\n",
       "      <td>7523</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>-1</td>\n",
       "      <td>1527</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-1</td>\n",
       "      <td>1874</td>\n",
       "      <td>-1</td>\n",
       "      <td>85</td>\n",
       "      <td>1451</td>\n",
       "      <td>106</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>69</td>\n",
       "      <td>2382</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>69</td>\n",
       "      <td>6885</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1487</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>69</td>\n",
       "      <td>6799</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1501</td>\n",
       "      <td>89</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>69</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1472</td>\n",
       "      <td>89</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>69</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1495</td>\n",
       "      <td>94</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>69</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1491</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>69</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1477</td>\n",
       "      <td>88</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>69</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1517</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>69</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1507</td>\n",
       "      <td>82</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  latitude  longitude  step   gsr  heart_rate  skin_temp  calories  \\\n",
       "368    33        -1         -1     0  1468         109         16        36   \n",
       "375    33        -1         -1     0  1539         114         16        41   \n",
       "376    33        -1         -1     0  1483         101         16        15   \n",
       "377    33        -1         -1     0  1495           4         16        56   \n",
       "378    33        -1         -1     0  1478           7         16        59   \n",
       "380    33        -1         -1     0  1451         118         15        44   \n",
       "381    33        -1         -1     0  1468           5         15        58   \n",
       "382    33        -1         -1     0  1465         112         15        37   \n",
       "384    33        -1         -1     0  1495         103         14        14   \n",
       "393    33        -1         -1     0    -1          -1         -1         8   \n",
       "409    33        -1         -1    61  1475          18         13        87   \n",
       "410    33        -1         -1     0    14          19         13        84   \n",
       "411    33        -1         -1    44   155          10         13        64   \n",
       "415    33        -1         -1    79    49         118         13        50   \n",
       "417    33        -1         -1    65   194         117         12        13   \n",
       "423    -1      7406         -1     0   101          16         11        89   \n",
       "428    -1      7494         -1     0     7          12         14        80   \n",
       "429    -1       907         -1     0   133           1         14        48   \n",
       "430    -1      7523         -1     0   106           0         14        42   \n",
       "435    -1      1527         -1     0   101          13         16        81   \n",
       "441    -1      1874         -1    85  1451         106          9        37   \n",
       "447    69      2382         -1     0    -1          91         -1         6   \n",
       "448    69      6885         -1     0  1487          90         11         9   \n",
       "450    69      6799         -1     0  1501          89         14         9   \n",
       "461    69        -1         -1     0  1472          89         17         9   \n",
       "464    69        -1         -1     0  1495          94         18         9   \n",
       "471    69        -1         -1     0  1491          90         20         8   \n",
       "474    69        -1         -1     0  1477          88         20         9   \n",
       "475    69        -1         -1     0  1517          90         20         9   \n",
       "478    69        -1         -1     0  1507          82         20         9   \n",
       "\n",
       "     risk_situation  \n",
       "368               1  \n",
       "375               0  \n",
       "376               1  \n",
       "377               0  \n",
       "378               0  \n",
       "380               0  \n",
       "381               0  \n",
       "382               1  \n",
       "384               1  \n",
       "393               1  \n",
       "409               1  \n",
       "410               0  \n",
       "411               0  \n",
       "415               1  \n",
       "417               1  \n",
       "423               1  \n",
       "428               1  \n",
       "429               1  \n",
       "430               1  \n",
       "435               1  \n",
       "441               1  \n",
       "447               1  \n",
       "448               1  \n",
       "450               1  \n",
       "461               1  \n",
       "464               1  \n",
       "471               1  \n",
       "474               1  \n",
       "475               1  \n",
       "478               1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = 0.05\n",
    "\n",
    "data = pd.DataFrame(dataset._data['input'])\n",
    "data = embeding(data)\n",
    "\n",
    "##on enleve fall et timestamp et fusion des classes\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = [\"timestamp\",\"name\", \"latitude\", \"longitude\", \"step\",\"gsr\",\"heart_rate\",\"skin_temp\",\"calories\",\"risk_situation\"]\n",
    "df.pop(\"timestamp\")\n",
    "\n",
    "df = df[df.risk_situation != -1]\n",
    "df = df[df.risk_situation != 0]\n",
    "df = df[df.risk_situation != 3]\n",
    "\n",
    "df.loc[df.risk_situation == 4 , 'risk_situation'] = 0\n",
    "df.loc[df.risk_situation == 2 , 'risk_situation'] = 0\n",
    "# df = df[pd.notnull(df['risk_situation'])]\n",
    "\n",
    "to_remove = np.random.choice(df[df['risk_situation']==1].index,size=15000,replace=False)\n",
    "df=df.drop(to_remove)\n",
    "stat = df['risk_situation'].value_counts(dropna=False)\n",
    "print(stat)\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "targets = df.pop('risk_situation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6678,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6678,)\n",
      "(4674, 8) (4674,)\n",
      "(1336, 8) (1336,)\n",
      "(668, 8) (668,)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "# targets = to_categorical(targets,2)\n",
    "\n",
    "print(targets.shape)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.values,\n",
    "                targets, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train,\n",
    "                y_train, test_size=0.125, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    4314\n",
      "0     360\n",
      "Name: 8, dtype: int64\n",
      "1.0    4314\n",
      "0.0    2880\n",
      "Name: 8, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train = np.column_stack((X_train,y_train))\n",
    "\n",
    "stat = pd.DataFrame(train)[8].value_counts(dropna=False)\n",
    "print(stat)\n",
    "\n",
    "newData_arr = data_augmentation(train, 0.05)\n",
    "X_train = np.concatenate((X_train,newData_arr[:,:8]))\n",
    "y_train = np.concatenate((y_train,newData_arr[:,8]))\n",
    "\n",
    "newData_arr = data_augmentation(train, 0.04)\n",
    "X_train = np.concatenate((X_train,newData_arr[:,:8]))\n",
    "y_train = np.concatenate((y_train,newData_arr[:,8]))\n",
    "\n",
    "newData_arr = data_augmentation(train, 0.06)\n",
    "X_train = np.concatenate((X_train,newData_arr[:,:8]))\n",
    "y_train = np.concatenate((y_train,newData_arr[:,8]))\n",
    "\n",
    "# newData_arr = data_augmentation(train, 0.055)\n",
    "# X_train = np.concatenate((X_train,newData_arr[:,:8]))\n",
    "# y_train = np.concatenate((y_train,newData_arr[:,8]))\n",
    "# \n",
    "# newData_arr = data_augmentation(train, 0.045)\n",
    "# X_train = np.concatenate((X_train,newData_arr[:,:8]))\n",
    "# y_train = np.concatenate((y_train,newData_arr[:,8]))\n",
    "# \n",
    "# newData_arr = data_augmentation(train, 0.0555)\n",
    "# X_train = np.concatenate((X_train,newData_arr[:,:8]))\n",
    "# y_train = np.concatenate((y_train,newData_arr[:,8]))\n",
    "# \n",
    "# newData_arr = data_augmentation(train, 0.0455)\n",
    "# X_train = np.concatenate((X_train,newData_arr[:,:8]))\n",
    "# y_train = np.concatenate((y_train,newData_arr[:,8]))\n",
    "\n",
    "train = np.column_stack((X_train,y_train))\n",
    "stat = pd.DataFrame(train)[8].value_counts(dropna=False)\n",
    "print(stat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7194 train sequences\n",
      "668 test sequences\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (7194, 8)\n",
      "x_test shape: (668, 8)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "#X_train = sequence.pad_sequences(X_train[:200], maxlen=maxlen)\n",
    "#X_test = sequence.pad_sequences(X_test[:200], maxlen=maxlen)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#X = X_train.reshape(len(X_train),3,3)\n",
    "#y = y_train.values.reshape(len(y_train), 1)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "testX = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
    "# trainY = np.reshape(y_train, (y_train.shape[0], 1, 1))\n",
    "# testY = np.reshape(y_test, (y_test.shape[0], 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7194, 1, 8) (7194,) (668, 1, 8) (668,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, y_train.shape, testX.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 553\n",
      "Trainable params: 553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.001)\n",
    "# create and fit the LSTM network\n",
    "print(\"Building model...\")\n",
    "model = Sequential()\n",
    "model.add(LSTM(8, input_shape=(1, 8)))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\n",
    "# model.compile(loss='mean_squared_error', optimizer=opt,metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train on 7194 samples, validate on 1336 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 2/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 3/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 4/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 5/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 6/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 7/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 8/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 9/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 10/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 11/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 12/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 13/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 14/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 15/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 16/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 17/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 18/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 19/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 20/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 21/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 22/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 23/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 24/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 25/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 26/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 27/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 28/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 29/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 30/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 31/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 32/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 33/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 34/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 35/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 36/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 37/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 38/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 39/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 40/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 41/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 42/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 43/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 44/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 45/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 46/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 47/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 48/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 49/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n",
      "Epoch 50/50\n",
      " - 0s - loss: 6.3823 - acc: 0.5997 - val_loss: 1.3246 - val_acc: 0.9169\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "history = LossHistory()\n",
    "csv_logger = CSVLogger('log.csv', append=False, separator=';')\n",
    "h = model.fit(trainX, y_train, epochs=50, batch_size=200, verbose=2,callbacks=[csv_logger],validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Acc maximum sur donnée de validation avec epoch\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9169161701630689\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(max(h.history['val_acc']))\n",
    "print(h.history['val_acc'].index(max(h.history['val_acc'])))\n",
    "      \n",
    "log = pd.read_csv('log.csv',sep=';')\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlim([0,50])\n",
    "\n",
    "log.plot(kind='line',x='epoch',y='acc',ax=ax)\n",
    "log.plot(kind='line',x='epoch',y='loss', color='red', ax=ax)\n",
    "\n",
    "log.plot(kind='line',x='epoch',y='val_acc',color='purple',ax=ax)\n",
    "log.plot(kind='line',x='epoch',y='val_loss', color='green', ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        55\n",
      "          1       0.92      1.00      0.96       613\n",
      "\n",
      "avg / total       0.84      0.92      0.88       668\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulj\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\core\\fromnumeric.py:56: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n",
      "C:\\Users\\paulj\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,  55],\n",
       "       [  0, 613]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict_classes(testX)\n",
    "y_test_rounded = np.argmax(y_test,axis=1)\n",
    "\n",
    "# print(y_test)\n",
    "# print(y_test)\n",
    "# \n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}